<a name="content">目录</a>

[学习笔记：机器学习实战](#title)
- [第一部分：分类算法](#part1-classification)
	- [1. k-近邻算法](#knn)
		- [1.1. 准备：导入数据](#knn-prepare-dataset)
		- [1.2. 实施kNN分类算法](#knn-carryout-knn)
		- [1.3. 示例1：使用kNN改进约会网站的配对效果](#knn-example1-dating-site)
		- [1.4. 示例2：手写识别系统](#knn-handwriting)




<h1 name="title">学习笔记：机器学习实战</h1>

<a name="part1-classification"><h2>第一部分：分类算法 [<sup>目录</sup>](#content)</h2></a>

<a name="knn"><h3>1. k-近邻算法 [<sup>目录</sup>](#content)</h3></a>

算法概述：

> 存在一个样本数据集，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。
> 
> 一般我们只选择样本数据集中前k个最相似的数据，通常k是不大于20的整数

<a name="knn-prepare-dataset"><h3>1.1. 准备：导入数据 [<sup>目录</sup>](#content)</h3></a>

```
import numpy as np
import operator

def createDataset():
	group = np.array([[1.0,1.1],
			[1.0,1.0],
			[0,0],
			[0,0.1]])
	lables = ['A','A','B','B']
	return group,lables
```

保存为`kNN.py`，为下一步将该函数作为模块导入做好准备

<a name="knn-carryout-knn"><h3>1.2. 实施kNN分类算法 [<sup>目录</sup>](#content)</h3></a>

```
import numpy as np
import operator

def kNN_classify(inX,dataset,lables,k):
	# 计算距离（欧式距离）
	datasetSize = dataset.shape[0]	# 训练样本数
	diffMat = np.tile(inX,(datasetSize,1))-dataset	# 将输入向量与训练集相减，得到每个特征的差值
	sqdiffMat = diffMat**2
	sqDistances = sqdiffMat.sum(axis=1)	# axis指定相加的方向，默认全部相加，axis=0指定列相加，axis=1指定行相加
	distances = sqDistances**0.5

	# 按照距离递增进行排序
	sortDistancesIndicies = distances.argsort()	# 对向量进行排序得到排序后的索引

	# 选择距离最小的k个点，并计算这k个点的lable的频率
	classCount = {}
	for i in range(k):
		voteLable = lables[sortDistancesIndicies[i]]
		classCount[voteLable] = classCount.get(voteLable,0) + 1

	# 返回前k个点中出现频率最高的类别
	##	items()方法将classCount字典分解成元组列表
	##	key=operator.itemgetter(1)，导入operator模块的itemgetter()方法，按照第二个元素的次序对元组进行排序
	##	reverse=True，默认为从小到大排序，即reverse=False
	sortedClassCount = sorted(classCount.items(),\
		key=operator.itemgetter(1),\
		reverse=True)
	return sortedClassCount[0][0]	
```

函数kNN_classify有4个参数：

> - inX：用于分类的输入向量
> - dataset：输入的训练样本集
> - lables：标签向量，其向量元素数目好矩阵dataset的行数相同
> - k：最近邻居数目

<a name="knn-example1-dating-site"><h3>1.3. 示例1：使用kNN改进约会网站的配对效果 [<sup>目录</sup>](#content)</h3></a>

问题描述：

> 海伦在约会网站上遇到的人可以分成以下三类：
> - 不喜欢的人
> - 魅力一般的人
> - 极具魅力的人
> 
> 想根据搜集到的数据将网站推荐的约会对象划分到这三个类别中

1. 准备数据

	海伦共搜集了1000个训练样本，每个样本包含以下3种特征：
	
	> - 每年获得的飞行常客里程数
	> - 玩游戏视频所耗时间百分比
	> - 每周消费的冰淇淋公升数
	
	这些数据保存在`datingTestSet2.txt`中，共四列，前三列为3种特征，最后一列为类别标签
	
	```
	40920	8.326976	0.953952	3
	14488	7.153469	1.673904	2
	26052	1.441871	0.805124	1
	75136	13.147394	0.428964	1
	38344	1.669788	0.134296	1
	```
	
	在将上述数据输入给分类器之前，必须将待处理的数据格式改变为分类器可以接受的格式
	
	```
	import numpy as np
	
	def file2matrix(filename):
		with open(filename,'r') as f:
			lines = f.readlines()
			numberOfLines = len(lines)
			featureMat = np.zeros((numberOfLines,3))	# 创建3列的0矩阵
			labels = []
			index = 0
			for line in lines:
				line = line.strip()
				lineSplit = line.split('\t')
				featureMat[index,:] = lineSplit[0:3]
				labels.append(int(lineSplit[-1]))
				index +=1
		return featureMat,labels
	```

2. 分析数据：使用Matplotlib创建散点图

	使用Matplotlib制作原始数据的散点图：
	
	```
	>>> import matplotlib
	>>> import matplotlib.pyplot as plt
	>>> fig = plt.figure() # 创建图片
	>>> ax = fig.add_subplot(111) # 创建1*1的图表矩阵，并设置当前子图序号为1
	>>> ax.scatter(dataset[:,1],dataset[:,2]) # 使用dataset矩阵中的第二、三列数据绘图
	>>> plt.show()
	```

	<p align="center"><img src=./picture/InActionML-chapter2-kNN-1.png width=600 /></p>

	为了从图中看出样本的分类信息，我们采用彩色或来标记不同的样本分类

	```
	>>> ax.scatter(dataset[:,1],dataset[:,2],15.0*np.array(labels),15.0*np.array(labels))
	```

	<p align="center"><img src=./picture/InActionML-chapter2-kNN-2.png width=600 /></p>

	若采用第一、二列数据绘制散点图，分类效果更好

	<p align="center"><img src=./picture/InActionML-chapter2-kNN-3.png width=600 /></p>

3. 准备数据：归一化数值

	```
	飞行里程	游戏时间比例	冰淇淋	类别
	40920	8.326976	0.953952	3
	14488	7.153469	1.673904	2
	26052	1.441871	0.805124	1
	75136	13.147394	0.428964	1
	38344	1.669788	0.134296	1
	```
	
	计算样本之间的距离时，数字差值最大的属性对计算结果的影响最大，很明显飞行里程数对于计算结果的影响将远远大于其他两个特征，而产生这种现象的唯一原因，仅仅是因为飞行里程数远远大于其他特征值。

	但是海伦认为这三个特征同等重要，因此作为等权重的三个特征之一，飞行里程数不应该如此严重地影响计算结果

	处理这种不同取值范围的特征值，通常采用数值归一化方法：
	
	```
	newValue = (oldValue-min)/(max-min)
	```

	```
	def autoNorm(dataset):
		minVals = dataset.min(0)
		maxVals = dataset.max(0)
		ranges = maxVals-minVals
		normDataset = np.zeros(dataset.shape)
		normDataset = (dataset-tile(minVals,(dataset.shape[0],1)))/tile(ranges,(dataset.shape[0],1)) # 对应特征值相除，并非矩阵除法
		return normDataset,ranges,minVals
	```

4. 测试算法

	提供已有数据的10%作为测试集，90%作为训练集，计算算法的预测正确率
	
	```
	# 将该函数加入kNN.py中作为kNN模块的一部分
	## 需要指定数据集文件，已经指定测试集比例
	
	def datingClassTest(filename,testPercent):
		dataset,labels = file2matrix(filename)
		normDataSet,ranges,minVals = autoNorm(dataset)
		totalNum = normDataSet.shape[0]
		testNum = totalNum*testPercent	# 测试集的样本数
		for i in range(testNum):
			result = kNN_classify(normDataSet[i,:],normDataSet[testNum:totalNum,:],labels[testNum:totalNum],3)
			print("The classifiler came back with:%d, the real answer is:%d",result,labels(i))
			if(result != labels(i)):
				errorCount += 1
		errorRate = errorCount/totalNum
		print("The total error rate is: %f",errorRate)
	```

<a name="knn-handwriting"><h3>1.4. 示例2：手写识别系统 [<sup>目录</sup>](#content)</h3></a>

问题描述：

> 为了简单起见，这里构造的系统只能识别数字0到9
> 
> 需要识别的数字已经用图像处理软件处理成宽高32*32的黑白图像

1. 准备数据：将图像转换为测试向量

	```
	def img2vec(filename):
		with open(filename,"r") as f:
			returnVec = np.zeros(1,1024)
			for i in range(32):
				line = f.readline()
				for j in range(32):
					returnVec[0,32*i+j] = line[j]
		return returnVec
	```

2. 测试算法：使用kNN识别手写数字

```
import os

def handwriteClassifierTest(trainDir,testDir,testPercent):
	hwLabels = []
	# 读进训练集
	trainFileList = os.listdir(trainDir)
	trainNum = len(trainFileList)
	trainMat = np.zeros(m,1024)
	for i in range(trainNum):
		trainFileName = trainFileList[i]
		classNumStr = trainFileName.split('_')[0]	# 从文件名中获得分类数字
		hwLabels.append(classNumStr)	# 保存分类数字
		trainMat[i,:] = img2vec(trainFileName)
	# 读进测试集并进行测试
	testFileList = os.listdir(testDir)
	testNum = len(testFileList)
	for i in range(testFileList):
		testFileName = testFileList[i]
		classNumStr = testFileName.split('_')[0]
		testVec = img2vec(testFileName)
		result = kNN_classifier(testVec,trainMat,hwLabels,3)
		print("The classifiler came back with:%d, the real answer is:%d",result,hwLabels(i))
		if(result != hwLabels(i)):
				errorCount += 1
	errorRate = errorCount/totalNum
	print("The total error rate is: %f",errorRate)	
```


---

参考资料：

(1) [美] Peter Harrington《机器学习实战》，人民邮电出版社
